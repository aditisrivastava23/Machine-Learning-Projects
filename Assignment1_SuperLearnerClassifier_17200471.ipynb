{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: The Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin  # 6 Base Classifiers for stacked ensemble \n",
    "from sklearn.naive_bayes import GaussianNB               # Naive Bayes\n",
    "from sklearn.tree import DecisionTreeClassifier          # Decision Tree\n",
    "from sklearn.neural_network import MLPClassifier         # Multi-layer Perceptron\n",
    "from sklearn import svm                                  # Support vector Machine\n",
    "from sklearn import linear_model                         # Logistic Regression\n",
    "from sklearn import neighbors                            # K-Nearest Neighbours\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn import neural_network\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Super Learner Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Super Learner* is a heterogeneous stacked ensemble classifier. This is a classification model that uses a set of base classifiers of different types, the outputs of which are then combined in another classifier at the stacked layer. The Super Learner was described in [(van der Laan et al, 2007)](https://pdfs.semanticscholar.org/19e9/c732082706f39d2ba12845851309714db135.pdf) but the stacked ensemble idea has been around for a long time. \n",
    "\n",
    "Figure 1 shows a flow diagram of the Super Learner process (this is from (van der Laan et al, 2007) and the process is also described in the COMP47590 lecture \"[COMP47590 2017-2018 L04 Supervised Learning Ensembles 3](https://www.dropbox.com/s/1ksx94nxtuyn4l8/COMP47590%202017-2018%20L04%20Supervised%20Learning%20Ensembles%203.pdf?raw=1)\"). The base classifiers are trained and their outputs are combined along with the training dataset labels into a training set for the stack layer classifier. To avoid overfitting the generation of the stacked layer training set uses a k-fold cross validation process (described as V-fold in Figure 1). To further add variety to the base estimators a bootstrapping selection (as is used in the bagging ensemble approach).\n",
    " \n",
    "![Super Learner Process Flow](SuperLearnerProcessFlow.png \"Logo Title Text 1\")\n",
    "Figure 1: A flow diagram for the Super Learner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the SuperLearnerClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class SuperLearnerClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregation model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "   ClassifierMixin : array of base classifiers for stacked ensemble \n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "    ----------\n",
    "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
    "            Super Learner. Statistical Applications in Genetics \n",
    "            and Molecular Biology, 6(1) \n",
    "            doi:10.2202/1544-6115.1309\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = SuperLearnerClassifier()\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self,stackClassifier=DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "            baseClassifiers=[DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,\\\n",
    "            min_samples_split=200),linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100)),svm.SVC(C=10,gamma=0.01,probability=True),\\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=6),GaussianNB()],useBaseProb=False,addOriginalData=False,base_folds=5):\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        stackClassifier : sklearn-classifier, the stack layer classifier to use\n",
    "        baseClassifiers : array of sklearn classifiers, list of base classifiers for the ensemble\n",
    "        useBaseProb     : Boolean, whether to use probablity distribution for stack layer instead of class labels \n",
    "        addOriginalData : Boolean, add original training data to output of base layer\n",
    "        base_folds      : integer, number of k-folds to train the ensemble layer\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"     \n",
    "        self.stackClassifier=stackClassifier\n",
    "        self.baseClassifiers=baseClassifiers\n",
    "        self.useBaseProb=useBaseProb\n",
    "        self.addOriginalData=addOriginalData\n",
    "        self.base_folds=base_folds\n",
    "        self.sl_train=pd.DataFrame()\n",
    "    \n",
    "    #Train the base classifiers and generate training data for stack layer classifier\n",
    "    def __ensembleLayer__(self,X,y):\n",
    "        # Split the data into k stratified folds for uniform distribution\n",
    "        skf = StratifiedKFold(n_splits=self.base_folds)\n",
    "        \n",
    "        # if useBaseProb is False, use class labels to train stack layer, \n",
    "        # else use probablity distributions to train stack layer\n",
    "        if not self.useBaseProb:\n",
    "            # train all base classifiers on each fold\n",
    "            for train_index, test_index in skf.split(X,y):\n",
    "                baseLabels=pd.DataFrame()\n",
    "                baseLabels['target']=y[test_index]\n",
    "\n",
    "                for counter, value in enumerate(self.baseClassifiers):\n",
    "                    value.fit(X.iloc[train_index],y[train_index])\n",
    "                    baseLabels['{}{}'.format('C', counter)]=value.predict(X.iloc[test_index])\n",
    "                # if addOriginalData is True, add the original training to \n",
    "                # the output of baseclassifiers to train stack layer\n",
    "                if self.addOriginalData:\n",
    "                    x=X.iloc[test_index].reset_index(drop=True)\n",
    "                    baseLabels=pd.concat([baseLabels,x],axis=1)\n",
    "\n",
    "                # Construct the training set for stack layer from predictions of each fold\n",
    "                self.sl_train=self.sl_train.append(baseLabels)\n",
    "        else:\n",
    "            # Use probablity distribution to train stack layer\n",
    "            for train_index, test_index in skf.split(X,y):\n",
    "                \n",
    "                classProb=pd.DataFrame()\n",
    "                classProb['target']=y[test_index]\n",
    "                for counter, value in enumerate(self.baseClassifiers):\n",
    "                    j=1\n",
    "                    value.fit(X.iloc[train_index],y[train_index])\n",
    "                    prob=value.predict_proba(X.iloc[test_index])\n",
    "                    for c in np.hsplit(prob, prob.shape[1]):\n",
    "                        classProb['{}{}{}'.format('p',counter,j)]=c\n",
    "                        j+=1\n",
    "                if self.addOriginalData:\n",
    "                        x=X.iloc[test_index].reset_index(drop=True)\n",
    "                        baseLabels=pd.concat([baseLabels,x],axis=1)\n",
    "                \n",
    "                self.sl_train=self.sl_train.append(classProb)\n",
    "        \n",
    "        # Retrain all base classifiers on the entire training set\n",
    "        for counter, value in enumerate(self.baseClassifiers):\n",
    "            value.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    # Function to train the stack layer classifier on the output of __ensemble_layer__\n",
    "    def __stackLayer__(self,X):\n",
    "        self.stackClassifier.fit(self.sl_train[self.sl_train.columns[1:]],np.array(self.sl_train[\"target\"]))\n",
    "        return self\n",
    "    \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_samples, n_features]\n",
    "            The training input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "        \"\"\" \n",
    "        # Check if training set is a dataframe, if not, convert to dataframe\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X=pd.DataFrame(X)\n",
    "            \n",
    "        # Call ensemble layer and stack layer functions to fit the superlearner\n",
    "        self.__ensembleLayer__(X,y)\n",
    "        self.__stackLayer__(X)              \n",
    "                    \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels of the input samples X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        Returns\n",
    "        -------\n",
    "        p : array of shape = [n_samples, ].\n",
    "            The predicted class labels of the input samples. \n",
    "        \"\"\"\n",
    "        # Check if X is a dataframe, if not, convert to dataframe\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X=pd.DataFrame(X)\n",
    "            \n",
    "        # check if fit function has been called before predicting\n",
    "        check_is_fitted(self,['stackClassifier','baseClassifiers','useBaseProb','addOriginalData','base_folds'])\n",
    "        \n",
    "        # create empty dataframe to store predictions of base layer\n",
    "        sl_input=pd.DataFrame()\n",
    "        \n",
    "        # if baseProbablity is not used, predict class labels and add it to training data for stack layer\n",
    "        if not self.useBaseProb:    \n",
    "            for counter, value in enumerate(self.baseClassifiers):\n",
    "                sl_input['{}{}'.format('C', counter)]=value.predict(X)\n",
    "                \n",
    "        # if baseProbability is used, predict class probabilities and add it to training data for stack layer\n",
    "        else:\n",
    "            for counter, value in enumerate(self.baseClassifiers):\n",
    "                    k=1\n",
    "                    prob=value.predict_proba(X)\n",
    "                    for c in np.hsplit(prob, prob.shape[1]):\n",
    "                        sl_input['{}{}{}'.format('p',counter,k)]=pd.Series(c.flatten())\n",
    "                        k+=1\n",
    "                        \n",
    "        # Check if the original training set has to be added to the stack layer training set\n",
    "        if self.addOriginalData:\n",
    "            X=X.reset_index(drop=True)                \n",
    "            sl_input=pd.concat([sl_input,X],axis=1)\n",
    "            \n",
    "        # Return the predictions from the superlearner\n",
    "        return self.stackClassifier.predict(sl_input)\n",
    "    \n",
    "    #Function to analyse the accuracy and diversity of the base estimators\n",
    "    def get_ensemble_strength(self,X,y):\n",
    "        \"\"\"\n",
    "        Find accuracy of all the models of the base estimators individually to predict classifier strength.\n",
    "        Find the similarity of the predictions made by each estimator. \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like matrix of shape = [n_samples, n_features]\n",
    "            The input samples. \n",
    "        y : array-like, shape = [n_samples] \n",
    "            The target values (class labels) as integers or strings.\n",
    "        Returns\n",
    "        -------\n",
    "        ensemble_accuracy   : Dictionary of accuracies of individual ensemble classifiers\n",
    "        matrix_diversity   : Pair-wise euclidean distance between confusion matrices of ensemble classifiers\n",
    "        diagonal_diversity : Pair-wise euclidean distance between the number of true positives of ensemble classifiers\n",
    "                             \n",
    "        \"\"\"\n",
    "        # Check if training set is a dataframe, if not, convert to dataframe\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X=pd.DataFrame(X)\n",
    "        #count number of class labels and base estimators\n",
    "        labels=len(np.unique(y))\n",
    "        n_classifiers=len(self.baseClassifiers)\n",
    "        #Create a hold out set for testing base estimators\n",
    "        X_train, X_hold, y_train, y_hold  = train_test_split(X, Y, random_state=0, train_size = 0.7)\n",
    "        #Create dictionary to store accuracies\n",
    "        ensemble_accuracy=dict()\n",
    "        stack_train_set=pd.DataFrame()\n",
    "        skf = StratifiedKFold(n_splits=self.base_folds)\n",
    "        \n",
    "        #Initialise each classifier accuracy to 0 for future aggregating and averaging after cross validation\n",
    "        for counter, value in enumerate(self.baseClassifiers):\n",
    "            ensemble_accuracy['{}{}'.format('Classifier',counter)] = 0\n",
    "            \n",
    "        # Generate predictions from each classifier using cross fold validation\n",
    "        # Aggregate accuracy of each classifier across folds\n",
    "        for train_index, test_index in skf.split(X_train,y_train):\n",
    "            baseLabels=pd.DataFrame()\n",
    "            baseLabels['target']=y_train[test_index]\n",
    "\n",
    "            for counter, value in enumerate(self.baseClassifiers):\n",
    "                    value.fit(X_train.iloc[train_index],y_train[train_index])\n",
    "                    y_pred=value.predict(X_train.iloc[test_index])\n",
    "                    baseLabels['{}{}'.format('C', counter)]=y_pred\n",
    "                    ensemble_accuracy['{}{}'.format('Classifier',counter)] += metrics.accuracy_score(y_train[test_index], y_pred)\n",
    "            stack_train_set=stack_train_set.append(baseLabels)\n",
    "            \n",
    "        # Find cross-validated average accuracy of each classifier and print them    \n",
    "        ensemble_accuracy.update((x, y/self.base_folds) for x, y in ensemble_accuracy.items())\n",
    "        \n",
    "        \n",
    "        # Find correlations between individual base estimators\n",
    "        # Weakly correlated estimators will make different kinds of errors,\n",
    "        # i.e. wrong predictions on different classes. The right predictions \n",
    "        # will also have different numbers for different classes in each estimator\n",
    "        # Cosine similarity will be a good measure of how different and similar are the predictions\n",
    "        # for each class\n",
    "        \n",
    "        #Create a 3D array to store the confusion matrices for each base classifier prediction on the hold-out set\n",
    "        predict_matrix=np.zeros((n_classifiers,labels,labels))\n",
    "        for counter, value in enumerate(self.baseClassifiers):\n",
    "            y_pred=value.predict(X_hold)\n",
    "            predict_matrix[counter]=metrics.confusion_matrix(y_hold, y_pred)\n",
    "        \n",
    "        # Calculate euclidean distance between confusion matrices of every classifier pair\n",
    "        # in the base ensembles list to find overall diversity of the predictions\n",
    "        # Calculate euclidean distance of the diagonals of the confusion matrices, \n",
    "        # this will tell us the diversity of the correct predictions.\n",
    "        # True positives will be where predicted label and true label are the same, hence the diagonals\n",
    "        matrix_similarity=np.zeros((n_classifiers,n_classifiers))\n",
    "        diagonal_similarity=np.zeros((n_classifiers,n_classifiers))\n",
    "        \n",
    "        for i, m1 in enumerate(predict_matrix):\n",
    "            for j, m2 in enumerate(predict_matrix):\n",
    "                if j>i:\n",
    "                    matrix_similarity[i][j]=np.linalg.norm(m1-m2)\n",
    "                    diagonal_similarity[i][j]=np.linalg.norm(np.diagonal(m1)-np.diagonal(m2))\n",
    "        \n",
    "        # Return the accuracy and similarity measures \n",
    "        return (ensemble_accuracy, matrix_similarity, diagonal_similarity)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the SuperLearnClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditi-PC\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.33333333,  0.33333333,  0.33333333])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "clf = SuperLearnerClassifier()\n",
    "iris = load_iris()\n",
    "clf.fit(iris.data, iris.target)\n",
    "cross_val_score(clf, iris.data, iris.target, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches (should be 5 - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise dict to store performance metrics of different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SuperLearner_Accuracy_comparisons=dict()\n",
    "Tuned_SuperLearner_info=dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42571</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42164</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29728</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "2840       2       0       0       0       0       0       0       0       0   \n",
       "42571      5       0       0       0       0       0       0       0       0   \n",
       "42164      9       0       0       0       0       0       0       0       0   \n",
       "29728      8       0       0       0       0       0       0       0       0   \n",
       "12002      4       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "2840        0    ...            0         0         0        47       100   \n",
       "42571       0    ...            0         0         0         0         0   \n",
       "42164       0    ...            0         0         0         0         0   \n",
       "29728       0    ...            0         0         0         0         0   \n",
       "12002       0    ...            0         0         0         0        58   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "2840         43        11         0         0         0  \n",
       "42571         0         0         0         0         0  \n",
       "42164         0         0         0         0         0  \n",
       "29728         0         0         0         0         0  \n",
       "12002       133       118         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data and its stratification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    325\n",
       "3    323\n",
       "0    322\n",
       "1    309\n",
       "7    306\n",
       "5    295\n",
       "4    286\n",
       "9    280\n",
       "6    279\n",
       "2    275\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.00000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.461000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.050667</td>\n",
       "      <td>0.221667</td>\n",
       "      <td>0.461667</td>\n",
       "      <td>0.822333</td>\n",
       "      <td>2.302667</td>\n",
       "      <td>5.35700</td>\n",
       "      <td>...</td>\n",
       "      <td>34.514000</td>\n",
       "      <td>22.998667</td>\n",
       "      <td>16.958333</td>\n",
       "      <td>17.525000</td>\n",
       "      <td>22.327667</td>\n",
       "      <td>17.855333</td>\n",
       "      <td>8.839000</td>\n",
       "      <td>2.708333</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.892047</td>\n",
       "      <td>0.054772</td>\n",
       "      <td>0.140194</td>\n",
       "      <td>0.244116</td>\n",
       "      <td>0.610648</td>\n",
       "      <td>2.823093</td>\n",
       "      <td>6.324597</td>\n",
       "      <td>7.769957</td>\n",
       "      <td>15.426829</td>\n",
       "      <td>23.04329</td>\n",
       "      <td>...</td>\n",
       "      <td>56.926596</td>\n",
       "      <td>48.249656</td>\n",
       "      <td>41.911042</td>\n",
       "      <td>43.435749</td>\n",
       "      <td>50.561901</td>\n",
       "      <td>45.815297</td>\n",
       "      <td>30.416379</td>\n",
       "      <td>17.854174</td>\n",
       "      <td>8.12045</td>\n",
       "      <td>1.226912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>232.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>199.00000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      4.461000     0.001000     0.004333     0.020667     0.050667   \n",
       "std       2.892047     0.054772     0.140194     0.244116     0.610648   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000     3.000000     7.000000     7.000000    21.000000   \n",
       "\n",
       "            pixel5       pixel6       pixel7       pixel8      pixel9  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.00000   \n",
       "mean      0.221667     0.461667     0.822333     2.302667     5.35700   \n",
       "std       2.823093     6.324597     7.769957    15.426829    23.04329   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "max      89.000000   188.000000   160.000000   219.000000   232.00000   \n",
       "\n",
       "          ...          pixel775     pixel776     pixel777     pixel778  \\\n",
       "count     ...       3000.000000  3000.000000  3000.000000  3000.000000   \n",
       "mean      ...         34.514000    22.998667    16.958333    17.525000   \n",
       "std       ...         56.926596    48.249656    41.911042    43.435749   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...         58.000000     9.000000     0.000000     0.000000   \n",
       "max       ...        244.000000   241.000000   250.000000   238.000000   \n",
       "\n",
       "          pixel779     pixel780     pixel781     pixel782    pixel783  \\\n",
       "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.00000   \n",
       "mean     22.327667    17.855333     8.839000     2.708333     0.64000   \n",
       "std      50.561901    45.815297    30.416379    17.854174     8.12045   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.00000   \n",
       "max     244.000000   240.000000   224.000000   248.000000   199.00000   \n",
       "\n",
       "          pixel784  \n",
       "count  3000.000000  \n",
       "mean      0.039000  \n",
       "std       1.226912  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max      63.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())\n",
    "if(dataset.select_dtypes(include=[np.object]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.object]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform data pre-processing and manipulation as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isolate the descriptive features and class labels\n",
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate a Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Super Learner Classifier using the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code here\n",
    "sl=SuperLearnerClassifier()\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.92      0.82       102\n",
      "          1       0.98      0.96      0.97       103\n",
      "          2       0.85      0.64      0.73        81\n",
      "          3       0.88      0.82      0.85        95\n",
      "          4       0.69      0.81      0.75        81\n",
      "          5       0.93      0.93      0.93        72\n",
      "          6       0.64      0.55      0.59        89\n",
      "          7       0.90      0.95      0.92        84\n",
      "          8       0.96      0.95      0.95        98\n",
      "          9       0.99      0.96      0.97        95\n",
      "\n",
      "avg / total       0.86      0.85      0.85       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>126</td>\n",
       "      <td>101</td>\n",
       "      <td>61</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>97</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3   4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0           94    1   1   1   0   0   4   0   1   0  102\n",
       "1            1   99   0   3   0   0   0   0   0   0  103\n",
       "2            2    0  52   1  14   0  12   0   0   0   81\n",
       "3            8    0   0  78   6   0   3   0   0   0   95\n",
       "4            0    0   3   5  66   0   7   0   0   0   81\n",
       "5            0    0   0   0   0  67   1   4   0   0   72\n",
       "6           21    1   5   1   7   2  49   0   3   0   89\n",
       "7            0    0   0   0   1   2   0  80   0   1   84\n",
       "8            0    0   0   0   2   0   1   2  93   0   98\n",
       "9            0    0   0   0   0   1   0   3   0  91   95\n",
       "All        126  101  61  89  96  72  77  89  97  92  900"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Default Parameters\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Experiment (Task 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a 10-fold cross validation experiment to evaluate the performance of the SuperLearnerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8125      0.83223684  0.84488449  0.84437086  0.83774834  0.84949833\n",
      "  0.86195286  0.82828283  0.81481481  0.84745763]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(sl, X, Y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Superlearner using Base Probablities (Task 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass a parameter specifying whether to use base classifiers probabilities instead of class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl=SuperLearnerClassifier(useBaseProb=True)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.79      0.81       102\n",
      "          1       0.99      0.96      0.98       103\n",
      "          2       0.83      0.62      0.71        81\n",
      "          3       0.83      0.79      0.81        95\n",
      "          4       0.71      0.74      0.73        81\n",
      "          5       0.84      0.96      0.90        72\n",
      "          6       0.49      0.58      0.53        89\n",
      "          7       0.95      0.86      0.90        84\n",
      "          8       0.74      0.86      0.80        98\n",
      "          9       0.99      0.94      0.96        95\n",
      "\n",
      "avg / total       0.82      0.81      0.81       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>107</td>\n",
       "      <td>76</td>\n",
       "      <td>113</td>\n",
       "      <td>90</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1   2   3   4   5    6   7    8   9  All\n",
       "True                                                     \n",
       "0          81    0   1   2   0   0   17   0    1   0  102\n",
       "1           0   99   0   3   0   0    1   0    0   0  103\n",
       "2           1    0  50   2  17   0   10   0    1   0   81\n",
       "3           3    0   0  75   1   0    9   0    7   0   95\n",
       "4           0    0   3   3  60   0    6   0    9   0   81\n",
       "5           0    0   0   0   0  69    0   0    2   1   72\n",
       "6          13    1   6   3   6   0   52   0    8   0   89\n",
       "7           0    0   0   0   0  11    0  72    1   0   84\n",
       "8           0    0   0   1   0   0   12   1   84   0   98\n",
       "9           0    0   0   1   0   2    0   3    0  89   95\n",
       "All        98  100  60  90  84  82  107  76  113  90  900"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Using Base Probabilities\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify stack layer classifier (Task 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a list of possible stack layer classifiers\n",
    "\"\"\"\n",
    "0: Decision Tree  \n",
    "1: Logistic Regression  \n",
    "2: Multi Layer Perceptron\n",
    "3: Support Vector Machine \n",
    "4: K-Nearest Neighbours\n",
    "5: Naive Bayes\n",
    "6: LinearSVC\n",
    "\"\"\"\n",
    "stackClassifiers=[DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "            linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100)),svm.SVC(C=10,gamma=0.01,probability=True),\\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=6),GaussianNB(),svm.LinearSVC(multi_class=\"ovr\",C=0.01)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with different stack layer classifiers from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(400, 200, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack Classifier : Multi Layer Perceptron\n",
    "#fit the superlearner\n",
    "sl=SuperLearnerClassifier(stackClassifier=stackClassifiers[2])\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.92      0.81       102\n",
      "          1       0.99      0.96      0.98       103\n",
      "          2       0.81      0.70      0.75        81\n",
      "          3       0.84      0.76      0.80        95\n",
      "          4       0.67      0.81      0.73        81\n",
      "          5       0.90      0.96      0.93        72\n",
      "          6       0.68      0.48      0.57        89\n",
      "          7       0.94      0.88      0.91        84\n",
      "          8       0.82      0.32      0.46        98\n",
      "          9       0.56      0.93      0.70        95\n",
      "\n",
      "avg / total       0.79      0.77      0.76       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>131</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>38</td>\n",
       "      <td>157</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3   4   5   6   7   8    9  All\n",
       "True                                                     \n",
       "0           94    0   1   2   1   0   3   0   0    1  102\n",
       "1            1   99   1   2   0   0   0   0   0    0  103\n",
       "2            3    0  57   4  12   0   5   0   0    0   81\n",
       "3            6    0   1  72  12   0   4   0   0    0   95\n",
       "4            1    0   5   5  66   0   4   0   0    0   81\n",
       "5            0    0   0   0   0  69   0   0   1    2   72\n",
       "6           24    1   5   1   7   2  43   3   2    1   89\n",
       "7            0    0   0   0   0   5   1  74   0    4   84\n",
       "8            2    0   0   0   1   0   2   1  31   61   98\n",
       "9            0    0   0   0   0   1   1   1   4   88   95\n",
       "All        131  100  70  86  99  77  63  79  38  157  900"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Stack Layer: Multi Layer Perceptron\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5, stackClassifier=GaussianNB(priors=None),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack Classifier : Naive Bayes\n",
    "#fit the superlearner\n",
    "sl=SuperLearnerClassifier(stackClassifier=stackClassifiers[5])\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.713333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.87      0.81       102\n",
      "          1       0.96      0.94      0.95       103\n",
      "          2       0.45      0.11      0.18        81\n",
      "          3       0.57      0.82      0.68        95\n",
      "          4       0.70      0.81      0.75        81\n",
      "          5       0.88      0.93      0.91        72\n",
      "          6       0.55      0.49      0.52        89\n",
      "          7       0.94      0.90      0.92        84\n",
      "          8       0.65      0.29      0.40        98\n",
      "          9       0.58      0.93      0.71        95\n",
      "\n",
      "avg / total       0.70      0.71      0.68       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>117</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>136</td>\n",
       "      <td>94</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>43</td>\n",
       "      <td>152</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2    3   4   5   6   7   8    9  All\n",
       "True                                                      \n",
       "0           89    0   2    1   0   0   9   0   0    1  102\n",
       "1            1   97   1    3   0   0   1   0   0    0  103\n",
       "2            5    2   9   44  13   0   8   0   0    0   81\n",
       "3            4    0   4   78   6   0   3   0   0    0   95\n",
       "4            0    0   1    7  66   0   7   0   0    0   81\n",
       "5            0    0   0    0   0  67   0   2   3    0   72\n",
       "6           17    2   3    3   9   7  44   0   3    1   89\n",
       "7            0    0   0    0   0   2   1  76   4    1   84\n",
       "8            1    0   0    0   0   0   6   2  28   61   98\n",
       "9            0    0   0    0   0   0   1   1   5   88   95\n",
       "All        117  101  20  136  94  76  80  81  43  152  900"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Stack Layer: Naive Bayes\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the Performance of Different Stack Layer Approaches (Task 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance of the ensemble when a label based stack layer training set and a probability based stack layer training set is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Class Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Using Decision Tree at stack layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack layer : Decision Tree\n",
    "sl=SuperLearnerClassifier(stackClassifier=stackClassifiers[0])\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.92      0.80       102\n",
      "          1       0.98      0.96      0.97       103\n",
      "          2       0.84      0.64      0.73        81\n",
      "          3       0.88      0.82      0.85        95\n",
      "          4       0.69      0.81      0.75        81\n",
      "          5       0.92      0.94      0.93        72\n",
      "          6       0.64      0.55      0.59        89\n",
      "          7       0.91      0.93      0.92        84\n",
      "          8       0.97      0.90      0.93        98\n",
      "          9       0.99      0.96      0.97        95\n",
      "\n",
      "avg / total       0.85      0.85      0.85       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>132</td>\n",
       "      <td>101</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3   4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0           94    1   1   1   0   0   4   0   1   0  102\n",
       "1            1   99   0   3   0   0   0   0   0   0  103\n",
       "2            2    0  52   1  14   0  12   0   0   0   81\n",
       "3            8    0   0  78   6   0   3   0   0   0   95\n",
       "4            0    0   3   5  66   0   7   0   0   0   81\n",
       "5            0    0   0   0   0  68   1   3   0   0   72\n",
       "6           22    1   6   1   7   1  49   0   2   0   89\n",
       "7            0    0   0   0   1   4   0  78   0   1   84\n",
       "8            5    0   0   0   2   0   1   2  88   0   98\n",
       "9            0    0   0   0   0   1   0   3   0  91   95\n",
       "All        132  101  62  89  96  74  77  86  91  92  900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Stack Layer: Decision Tree\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Using Logistic Regression at stack layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack layer : Logistic Regression\n",
    "sl=SuperLearnerClassifier(stackClassifier=stackClassifiers[1])\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.52      0.52       102\n",
      "          1       0.73      0.94      0.83       103\n",
      "          2       0.29      0.16      0.21        81\n",
      "          3       0.53      0.81      0.64        95\n",
      "          4       0.38      0.07      0.12        81\n",
      "          5       0.64      0.89      0.74        72\n",
      "          6       0.35      0.21      0.26        89\n",
      "          7       0.89      0.86      0.87        84\n",
      "          8       0.30      0.24      0.27        98\n",
      "          9       0.49      0.74      0.59        95\n",
      "\n",
      "avg / total       0.51      0.55      0.51       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>101</td>\n",
       "      <td>132</td>\n",
       "      <td>45</td>\n",
       "      <td>146</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>143</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2    3   4    5   6   7   8    9  All\n",
       "True                                                       \n",
       "0           53   29   7    2   1    7   2   0   0    1  102\n",
       "1            1   97   2    3   0    0   0   0   0    0  103\n",
       "2           31    0  13   13   5    7   9   0   3    0   81\n",
       "3            3    2   7   77   0    0   5   0   1    0   95\n",
       "4            1    0  10   38   6    8  17   0   1    0   81\n",
       "5            0    0   0    0   0   64   0   6   2    0   72\n",
       "6           11    4   6   10   4    5  19   1  26    3   89\n",
       "7            0    0   0    1   0    7   0  72   2    2   84\n",
       "8            1    0   0    2   0    1   2   1  24   67   98\n",
       "9            0    0   0    0   0    1   1   1  22   70   95\n",
       "All        101  132  45  146  16  100  55  81  81  143  900"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Stack Layer: Logistic Regression\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Class Probablities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Using Decision Tree at stack layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack layer : Decision Tree\n",
    "sl=SuperLearnerClassifier(stackClassifier=stackClassifiers[0], useBaseProb=True)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.76      0.82       102\n",
      "          1       0.98      0.96      0.97       103\n",
      "          2       0.83      0.60      0.70        81\n",
      "          3       0.87      0.79      0.83        95\n",
      "          4       0.71      0.73      0.72        81\n",
      "          5       0.91      0.94      0.93        72\n",
      "          6       0.47      0.63      0.54        89\n",
      "          7       0.93      0.92      0.92        84\n",
      "          8       0.75      0.87      0.81        98\n",
      "          9       0.97      0.95      0.96        95\n",
      "\n",
      "avg / total       0.83      0.82      0.82       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>88</td>\n",
       "      <td>101</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>119</td>\n",
       "      <td>83</td>\n",
       "      <td>113</td>\n",
       "      <td>93</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1   2   3   4   5    6   7    8   9  All\n",
       "True                                                     \n",
       "0          78    1   1   2   0   0   19   0    1   0  102\n",
       "1           0   99   0   3   0   0    1   0    0   0  103\n",
       "2           0    0  49   2  17   0   12   0    1   0   81\n",
       "3           0    0   0  75   1   0   12   0    7   0   95\n",
       "4           0    0   3   2  59   0    7   0   10   0   81\n",
       "5           0    0   0   0   0  68    0   2    1   1   72\n",
       "6          10    1   6   2   6   0   56   0    8   0   89\n",
       "7           0    0   0   0   0   5    0  77    0   2   84\n",
       "8           0    0   0   0   0   0   12   1   85   0   98\n",
       "9           0    0   0   0   0   2    0   3    0  90   95\n",
       "All        88  101  59  86  83  75  119  83  113  93  900"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"With BaseProb, Stack Layer: Decision Tree\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Using Logistic Regression at stack layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "            useBaseProb=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack layer : Logistic Regression\n",
    "sl=SuperLearnerClassifier(stackClassifier=stackClassifiers[1], useBaseProb=True)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.871111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.84       102\n",
      "          1       0.98      0.97      0.98       103\n",
      "          2       0.80      0.74      0.77        81\n",
      "          3       0.84      0.93      0.88        95\n",
      "          4       0.76      0.79      0.78        81\n",
      "          5       0.93      0.93      0.93        72\n",
      "          6       0.68      0.56      0.61        89\n",
      "          7       0.93      0.95      0.94        84\n",
      "          8       0.94      0.97      0.95        98\n",
      "          9       0.99      0.96      0.97        95\n",
      "\n",
      "avg / total       0.87      0.87      0.87       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>109</td>\n",
       "      <td>102</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2    3   4   5   6   7    8   9  All\n",
       "True                                                      \n",
       "0           89    1   2    4   0   0   5   0    1   0  102\n",
       "1            0  100   0    2   0   0   1   0    0   0  103\n",
       "2            0    0  60    1  12   0   8   0    0   0   81\n",
       "3            1    0   1   88   4   0   1   0    0   0   95\n",
       "4            0    0   3    7  64   0   7   0    0   0   81\n",
       "5            0    0   0    0   0  67   1   3    0   1   72\n",
       "6           18    1   9    2   4   0  50   0    5   0   89\n",
       "7            0    0   0    0   0   4   0  80    0   0   84\n",
       "8            0    0   0    1   0   0   1   1   95   0   98\n",
       "9            1    0   0    0   0   1   0   2    0  91   95\n",
       "All        109  102  75  105  84  72  74  86  101  92  900"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"With BaseProb, Stack Layer: Logistic Regression\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the base estimators to use (Task 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of base estimators and pass subsets of list or whole list as the BaseEstimator parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create different lists of possible combinations of base layer classifiers\n",
    "\"\"\"\n",
    "0: Decision Tree  \n",
    "1: Logistic Regression  \n",
    "2: Multi Layer Perceptron\n",
    "3: Support Vector Machine \n",
    "4: K-Nearest Neighbours\n",
    "5: Naive Bayes\n",
    "6: LinearSVC\n",
    "\"\"\"\n",
    "# Comnination of 7 different base classifiers\n",
    "baseLearners1=[DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "            linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100)),svm.SVC(C=10,gamma=0.01,probability=True),\\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=6),GaussianNB()]\n",
    "\n",
    "# Combination of 3 different base classifiers : SVM, Logistic Regression, Multi Layer perceptron with 2 of each \n",
    "baseLearners2=[svm.SVC(C=10,gamma=0.01,probability=True),svm.SVC(C=10,gamma=0.01,probability=True),\\\n",
    "            linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100)),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100))]\n",
    "\n",
    "# Combination of 5 different base classifiers : Decision Tree, Logistic Regression, KNN, 2 Multi Layer perceptrons \n",
    "baseLearners3=[DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "            linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=6),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400)),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400))]\n",
    "\n",
    "# Combination of 4 different base classifiers : Logistic Regression, SVM, Multi Layer perceptrons, Naive Bayes \n",
    "baseLearners4=[linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            svm.SVC(C=10,gamma=0.01,probability=True),MLPClassifier(alpha=0.1,hidden_layer_sizes=(400)),GaussianNB()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance of each combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...c_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baselearners1\n",
    "sl=SuperLearnerClassifier(baseClassifiers=baseLearners1)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.92      0.82       102\n",
      "          1       0.98      0.96      0.97       103\n",
      "          2       0.85      0.64      0.73        81\n",
      "          3       0.90      0.81      0.85        95\n",
      "          4       0.69      0.81      0.75        81\n",
      "          5       0.92      0.96      0.94        72\n",
      "          6       0.61      0.55      0.58        89\n",
      "          7       0.92      0.94      0.93        84\n",
      "          8       0.96      0.95      0.95        98\n",
      "          9       0.99      0.96      0.97        95\n",
      "\n",
      "avg / total       0.86      0.85      0.85       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>126</td>\n",
       "      <td>101</td>\n",
       "      <td>61</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3   4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0           94    1   1   1   0   0   4   0   1   0  102\n",
       "1            1   99   0   2   0   0   1   0   0   0  103\n",
       "2            2    0  52   1  14   0  12   0   0   0   81\n",
       "3            8    0   0  77   6   0   4   0   0   0   95\n",
       "4            0    0   3   4  66   0   8   0   0   0   81\n",
       "5            0    0   0   0   0  69   1   2   0   0   72\n",
       "6           21    1   5   1   7   2  49   0   3   0   89\n",
       "7            0    0   0   0   1   3   0  79   0   1   84\n",
       "8            0    0   0   0   2   0   1   2  93   0   98\n",
       "9            0    0   0   0   0   1   0   3   0  91   95\n",
       "All        126  101  61  86  96  75  80  86  97  92  900"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"BaseLearners1\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with second list of baseLearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False), SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  deci...e=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baselearners2\n",
    "sl=SuperLearnerClassifier(baseClassifiers=baseLearners2)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865555555556\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.84       102\n",
      "          1       0.98      0.96      0.97       103\n",
      "          2       0.84      0.70      0.77        81\n",
      "          3       0.88      0.84      0.86        95\n",
      "          4       0.71      0.83      0.76        81\n",
      "          5       0.92      0.96      0.94        72\n",
      "          6       0.68      0.58      0.63        89\n",
      "          7       0.91      0.94      0.92        84\n",
      "          8       0.96      0.95      0.95        98\n",
      "          9       0.99      0.96      0.97        95\n",
      "\n",
      "avg / total       0.87      0.87      0.86       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>118</td>\n",
       "      <td>101</td>\n",
       "      <td>68</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "      <td>97</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3   4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0           92    1   2   2   0   0   4   0   1   0  102\n",
       "1            1   99   0   3   0   0   0   0   0   0  103\n",
       "2            1    0  57   1  14   0   8   0   0   0   81\n",
       "3            5    0   0  80   6   0   4   0   0   0   95\n",
       "4            0    0   3   4  67   0   7   0   0   0   81\n",
       "5            0    0   0   0   0  69   0   3   0   0   72\n",
       "6           19    1   6   1   7   0  52   0   3   0   89\n",
       "7            0    0   0   0   0   4   0  79   0   1   84\n",
       "8            0    0   0   0   1   1   1   2  93   0   98\n",
       "9            0    0   0   0   0   1   0   3   0  91   95\n",
       "All        118  101  68  91  95  75  76  87  97  92  900"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"BaseLearners2\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with third list of baseLearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, rand...e=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baselearners3\n",
    "sl=SuperLearnerClassifier(baseClassifiers=baseLearners3)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.90      0.83       102\n",
      "          1       0.97      0.96      0.97       103\n",
      "          2       0.72      0.69      0.70        81\n",
      "          3       0.86      0.82      0.84        95\n",
      "          4       0.73      0.83      0.77        81\n",
      "          5       0.97      0.92      0.94        72\n",
      "          6       0.64      0.52      0.57        89\n",
      "          7       0.94      0.94      0.94        84\n",
      "          8       0.95      0.95      0.95        98\n",
      "          9       0.96      0.97      0.96        95\n",
      "\n",
      "avg / total       0.85      0.85      0.85       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>119</td>\n",
       "      <td>102</td>\n",
       "      <td>78</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3   4   5   6   7   8   9  All\n",
       "True                                                    \n",
       "0           92    1   3   1   0   0   4   0   1   0  102\n",
       "1            1   99   0   3   0   0   0   0   0   0  103\n",
       "2            1    0  56   1  14   0   9   0   0   0   81\n",
       "3            5    1   2  78   7   0   2   0   0   0   95\n",
       "4            0    0   4   5  67   0   5   0   0   0   81\n",
       "5            0    0   0   0   0  66   2   2   0   2   72\n",
       "6           19    1  13   2   4   0  46   0   4   0   89\n",
       "7            0    0   0   0   0   2   1  79   0   2   84\n",
       "8            1    0   0   1   0   0   2   1  93   0   98\n",
       "9            0    0   0   0   0   0   1   2   0  92   95\n",
       "All        119  102  78  91  92  68  72  84  98  96  900"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"BaseLearners3\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with fourth list of baseLearners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=False,\n",
       "            baseClassifiers=[LogisticRegression(C=0.2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False), SVC(C=10, cache_...l=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False), GaussianNB(priors=None)],\n",
       "            base_folds=5,\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baselearners4\n",
    "sl=SuperLearnerClassifier(baseClassifiers=baseLearners4)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.89      0.83       102\n",
      "          1       0.98      0.96      0.97       103\n",
      "          2       0.85      0.64      0.73        81\n",
      "          3       0.89      0.84      0.86        95\n",
      "          4       0.63      0.83      0.72        81\n",
      "          5       0.96      0.96      0.96        72\n",
      "          6       0.68      0.58      0.63        89\n",
      "          7       0.91      0.95      0.93        84\n",
      "          8       0.96      0.95      0.95        98\n",
      "          9       0.99      0.96      0.97        95\n",
      "\n",
      "avg / total       0.87      0.86      0.86       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>117</td>\n",
       "      <td>101</td>\n",
       "      <td>61</td>\n",
       "      <td>90</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>97</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   2   3    4   5   6   7   8   9  All\n",
       "True                                                     \n",
       "0           91    1   1   2    2   0   4   0   1   0  102\n",
       "1            2   99   0   2    0   0   0   0   0   0  103\n",
       "2            1    0  52   1   19   0   8   0   0   0   81\n",
       "3            5    0   0  80    6   0   4   0   0   0   95\n",
       "4            0    0   3   4   67   0   7   0   0   0   81\n",
       "5            0    0   0   0    0  69   0   3   0   0   72\n",
       "6           18    1   5   1    9   0  52   0   3   0   89\n",
       "7            0    0   0   0    1   2   0  80   0   1   84\n",
       "8            0    0   0   0    2   0   1   2  93   0   98\n",
       "9            0    0   0   0    0   1   0   3   0  91   95\n",
       "All        117  101  61  90  106  72  76  88  97  92  900"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a set of predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"BaseLearners4\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Through SuperLearnerClassifier Architectures & Parameters (Task 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfrom a grid search experiment to detemrine the optimal architecture and hyper-parameter values for the SuperLearnClasssifier for the MNIST Fashion classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'baseClassifiers': [baseLearners1, baseLearners2, baseLearners3,baseLearners4], \n",
    "               'stackClassifier': [DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "            linear_model.LogisticRegression(C=0.2,max_iter=1000,multi_class=\"ovr\",solver=\"liblinear\"),\\\n",
    "            MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100)),svm.SVC(C=10,gamma=0.01,probability=True),\\\n",
    "            neighbors.KNeighborsClassifier(n_neighbors=6),GaussianNB()]\n",
    "               'useBaseProb':[False,True]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "tuned_superlearner = GridSearchCV(SuperLearnerClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "tuned_superlearner.fit(X_train, y_train)\n",
    "\n",
    "# Print details\n",
    "print(\"Best set of parameters found on the training set:\")\n",
    "print(tuned_superlearner.best_params_)\n",
    "print(tuned_superlearner.best_score_)\n",
    "\n",
    "# Store the details\n",
    "Tuned_SuperLearner_info[\"Parameters\"]=tuned_superlearner.best_params_\n",
    "Tuned_SuperLearner_info[\"Best Score\"]=tuned_superlearner.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the model selected by the grid search on a hold-out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = tuned_superlearner.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "#model_test_accuracy_comparisons[\"Tuned SVC\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Tuned SuperLearner\"]=accuracy\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Impact of Adding Original Descriptive Features at the Stack Layer (Task 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the impact of adding original descriptive features at the stack layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearnerClassifier(addOriginalData=True,\n",
       "            baseClassifiers=[SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False), SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  deci...e=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)],\n",
       "            base_folds=5,\n",
       "            sl_train=     target  C0  C1  C2  C3  C4  C5  pixel1  pixel2    pixel3    ...     \\\n",
       "0         7   7   7   7   7   7   7     0.0     0.0  0.000000    ...\n",
       "1         9   7   7   7   7   7   7     0.0     0.0  0.000000    ...\n",
       "2         4   4   4   4   4   4   4     0.0     0.0  0.000000    ....\n",
       "414  0.000000  0.000000       0.0\n",
       "415  0.105882  0.121569       0.0\n",
       "\n",
       "[2100 rows x 791 columns],\n",
       "            stackClassifier=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "            useBaseProb=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SuperLearner by adding original training data to stack layer along with base classifier predictions \n",
    "# Using best hyperparameters found using GridSearch in the previous step\n",
    "sl=SuperLearnerClassifier(**tuned_superLearner.best_params_,addOriginalData=True)\n",
    "sl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.83      0.80        83\n",
      "          1       0.94      0.98      0.96        84\n",
      "          2       0.76      0.71      0.73        96\n",
      "          3       0.82      0.75      0.78        83\n",
      "          4       0.48      0.79      0.60        86\n",
      "          5       0.86      0.78      0.82        92\n",
      "          6       0.77      0.45      0.57        97\n",
      "          7       0.85      0.96      0.90        89\n",
      "          8       0.95      0.87      0.91        79\n",
      "          9       0.98      0.91      0.94       111\n",
      "\n",
      "avg / total       0.82      0.80      0.80       900\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>141</td>\n",
       "      <td>84</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>103</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3    4   5   6    7   8    9  All\n",
       "True                                                     \n",
       "0          69   1   1   4    4   1   1    0   2    0   83\n",
       "1           0  82   0   1    1   0   0    0   0    0   84\n",
       "2           2   0  68   1   18   0   7    0   0    0   96\n",
       "3           6   2   0  62   12   0   1    0   0    0   83\n",
       "4           0   1   9   4   68   0   3    0   1    0   86\n",
       "5           1   0   0   0    8  72   0    9   1    1   92\n",
       "6          11   0  12   4   23   3  44    0   0    0   97\n",
       "7           0   0   0   0    0   3   0   85   0    1   89\n",
       "8           0   1   0   0    5   2   1    1  69    0   79\n",
       "9           0   0   0   0    2   3   0    5   0  101  111\n",
       "All        89  87  90  76  141  84  57  100  73  103  900"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make predictions for the test data\n",
    "y_pred = sl.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "SuperLearner_Accuracy_comparisons[\"Tuned SuperLearner with Original Data\"]=accuracy\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print and plot the accuracies of different parameter configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BaseLearners1': 0.85444444444444445,\n",
       " 'BaseLearners2': 0.86555555555555552,\n",
       " 'BaseLearners3': 0.85333333333333339,\n",
       " 'BaseLearners4': 0.85999999999999999,\n",
       " 'Default Parameters': 0.85444444444444445,\n",
       " 'Stack Layer: Decision Tree': 0.84777777777777774,\n",
       " 'Stack Layer: Logistic Regression': 0.55000000000000004,\n",
       " 'Stack Layer: Multi Layer Perceptron': 0.77000000000000002,\n",
       " 'Stack Layer: Naive Bayes': 0.71333333333333337,\n",
       " 'Using Base Probabilities': 0.81222222222222218,\n",
       " 'With BaseProb, Stack Layer: Decision Tree': 0.81777777777777783,\n",
       " 'With BaseProb, Stack Layer: Logistic Regression': 0.87111111111111106}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(SuperLearner_Accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the accuracies to compare the different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAD8CAYAAACin3p3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae8bda7eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(SuperLearner_Accuracy_comparisons)), list(SuperLearner_Accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(SuperLearner_Accuracy_comparisons)), list(SuperLearner_Accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Ensemble Model (Task 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an analysis to investigate the strength of the base estimators and the strengths of the correlations between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the strength and correlation of the default base Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of an ensemble relies on the strength of the individual estimators and the diversity between them. Ideally, we would like to have strong individual accuracy while also having diverse predictions, i.e., each classifier of the ensemble makes mistakes with different predictions. This helps the classifiers to learn from each others mistakes while good individual accuracy helps strengthen the learning. \n",
    "In the ensemble strength measuring function used here, accuracy of each classifier in the ensemble has been calculated by using cross-fold validation on the training set. To measure diversity, Euclidean distance between pairs of confusion matrices of each classifier's prediction on the hold-out data set has been used. The rationale behind this is, if the classifiers are weakly correlated, their confusion matrices will be very different from each other. Moreover, the number of correct predictions for each label will also differ for them. So as a measure of overall diversity, pair-wise Euclidean Distance between confusion matrices have been calculated. Also, to measure the diversity of correct predictions, which are present in the diagonals of the confusion matrix, Euclidean distance between the diagonals of every confusion matrix has also been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Estimator Accuracies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Classifier0': 0.67095286330129356,\n",
       " 'Classifier1': 0.81861813748799206,\n",
       " 'Classifier2': 0.82762748767048555,\n",
       " 'Classifier3': 0.84479703541037421,\n",
       " 'Classifier4': 0.7552591981790524,\n",
       " 'Classifier5': 0.49665405405697233}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Overall diversity:\n",
      "     0          1          2          3          4           5\n",
      "0  0.0  72.111026  71.958321  73.402997  61.122827  164.383697\n",
      "1  0.0   0.000000  14.696938  13.341664  34.176015  179.320941\n",
      "2  0.0   0.000000   0.000000  15.033296  36.878178  180.122181\n",
      "3  0.0   0.000000   0.000000   0.000000  34.234486  181.653516\n",
      "4  0.0   0.000000   0.000000   0.000000   0.000000  163.713164\n",
      "5  0.0   0.000000   0.000000   0.000000   0.000000    0.000000\n",
      "---------------------------\n",
      "Diversity of correct predictions:\n",
      "     0          1          2          3          4           5\n",
      "0  0.0  57.236352  57.297469  59.084685  45.044423  105.242577\n",
      "1  0.0   0.000000  11.357817   7.937254  25.238859  132.037873\n",
      "2  0.0   0.000000   0.000000   7.615773  26.832816  133.719856\n",
      "3  0.0   0.000000   0.000000   0.000000  26.832816  136.180028\n",
      "4  0.0   0.000000   0.000000   0.000000   0.000000  114.468336\n",
      "5  0.0   0.000000   0.000000   0.000000   0.000000    0.000000\n"
     ]
    }
   ],
   "source": [
    "sl=SuperLearnerClassifier()\n",
    "ensemble_accuracy, matrix_diversity, diagonal_diversity=sl.get_ensemble_strength(X,Y)\n",
    "\n",
    "print(\"Base Estimator Accuracies:\")\n",
    "display(ensemble_accuracy)\n",
    "print(\"---------------------------\")\n",
    "print(\"Overall diversity:\")\n",
    "print(pd.DataFrame(matrix_diversity))\n",
    "print(\"---------------------------\")\n",
    "print(\"Diversity of correct predictions:\")\n",
    "print(pd.DataFrame(diagonal_diversity))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the strength and correlation of a less diverse set of base Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Estimator Accuracies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Classifier0': 0.67095286330129356,\n",
       " 'Classifier1': 0.67142679695058261,\n",
       " 'Classifier2': 0.49665405405697233}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Overall diversity:\n",
      "     0    1           2\n",
      "0  0.0  0.0  164.383697\n",
      "1  0.0  0.0  164.383697\n",
      "2  0.0  0.0    0.000000\n",
      "---------------------------\n",
      "Diversity of correct predictions:\n",
      "     0    1           2\n",
      "0  0.0  0.0  105.242577\n",
      "1  0.0  0.0  105.242577\n",
      "2  0.0  0.0    0.000000\n"
     ]
    }
   ],
   "source": [
    "sl=SuperLearnerClassifier(baseClassifiers=[DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "                                          DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "                         GaussianNB()],stackClassifier=MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100)))\n",
    "ensemble_accuracy, matrix_diversity, diagonal_diversity=sl.get_ensemble_strength(X,Y)\n",
    "\n",
    "print(\"Base Estimator Accuracies:\")\n",
    "display(ensemble_accuracy)\n",
    "print(\"---------------------------\")\n",
    "print(\"Overall diversity:\")\n",
    "print(pd.DataFrame(matrix_diversity))\n",
    "print(\"---------------------------\")\n",
    "print(\"Diversity of correct predictions:\")\n",
    "print(pd.DataFrame(diagonal_diversity))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse diversity of another configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Estimator Accuracies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Classifier0': 0.67142679695058261,\n",
       " 'Classifier1': 0.67142679695058261,\n",
       " 'Classifier2': 0.49665405405697233,\n",
       " 'Classifier3': 0.82052749962786531}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Overall diversity:\n",
      "     0    1           2           3\n",
      "0  0.0  0.0  164.383697   70.512410\n",
      "1  0.0  0.0  164.383697   70.512410\n",
      "2  0.0  0.0    0.000000  186.150477\n",
      "3  0.0  0.0    0.000000    0.000000\n",
      "---------------------------\n",
      "Diversity of correct predictions:\n",
      "     0    1           2           3\n",
      "0  0.0  0.0  105.242577   54.230987\n",
      "1  0.0  0.0  105.242577   54.230987\n",
      "2  0.0  0.0    0.000000  136.546695\n",
      "3  0.0  0.0    0.000000    0.000000\n"
     ]
    }
   ],
   "source": [
    "sl=SuperLearnerClassifier(baseClassifiers=[DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "                                          DecisionTreeClassifier(criterion=\"entropy\",max_depth=24,min_samples_split=200),\\\n",
    "                         GaussianNB(),MLPClassifier(alpha=0.1,hidden_layer_sizes=(400, 200, 100))])\n",
    "ensemble_accuracy, matrix_diversity, diagonal_diversity=sl.get_ensemble_strength(X,Y)\n",
    "\n",
    "print(\"Base Estimator Accuracies:\")\n",
    "display(ensemble_accuracy)\n",
    "print(\"---------------------------\")\n",
    "print(\"Overall diversity:\")\n",
    "print(pd.DataFrame(matrix_diversity))\n",
    "print(\"---------------------------\")\n",
    "print(\"Diversity of correct predictions:\")\n",
    "print(pd.DataFrame(diagonal_diversity))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
